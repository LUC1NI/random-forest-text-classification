1. Introdu√ß√£o
O objetivo deste trabalho √© avaliar o desempenho de um classificador Random Forest aplicado a tr√™s bases de dados de classifica√ß√£o de texto supervisionada, contendo avalia√ß√µes e mensagens anotadas com classes positivas (1) ou negativas (0).
 As bases utilizadas foram:
Amazon Cells Labelled


Yelp Labelled


IMDB Labelled


Todas possuem formato text<TAB>target e foram processadas no Google Colab, utilizando TF-IDF para vetoriza√ß√£o dos textos.

2. Metodologia
As etapas seguidas foram:
Carregamento das bases no Colab via files.upload().


Padroniza√ß√£o das colunas para text e target.


An√°lise de balanceamento das classes.


Divis√£o em treino (75%) e teste (25%) utilizando train_test_split.


Vetoriza√ß√£o TF-IDF para transformar o texto em espa√ßo vetorial.


Treinamento com RandomForestClassifier (par√¢metros padr√£o).


Avalia√ß√£o com m√©tricas:


Accuracy (acur√°cia)


Precision (precis√£o)


Recall (revoca√ß√£o)


AUC (√°rea sob a curva ROC)


Plotagem da curva ROC para an√°lise visual do desempenho.



3. Resultados
3.1. Balanceamento das Classes
Todas as bases apresentam classes relativamente balanceadas entre positivo (1) e negativo (0), com pequenas varia√ß√µes.
Base
Classe 0 (%)
Classe 1 (%)
Amazon
50%
50%
Yelp
50%
50%
IMDB
48.3%
51.6%


3.2. M√©tricas de Avalia√ß√£o
Base
Accuracy
Precision
Recall
AUC
Amazon
0.748
0.756
0.782
0.876
Yelp
0.78
0.80
0.72
0.82
IMDB
0.695
0.677
0.714
0.760


Amazon: A acur√°cia de 0.748 mostra que o modelo acerta em m√©dia 74,8% das previs√µes. A precis√£o de 0.756 indica que, quando o modelo prev√™ positivo, ele acerta cerca de 75,6% das vezes. O recall de 0.782 significa que ele consegue recuperar a maioria dos exemplos realmente positivos. Como a base √© balanceada, esses valores s√£o consistentes e n√£o inflados artificialmente.


Yelp: Apresentou a maior acur√°cia (0.78), com precis√£o de 0.80, indicando bom desempenho ao prever positivos com baixa taxa de falsos positivos. O recall foi menor (0.72), sugerindo que alguns positivos ainda foram perdidos.


IMDB: Foi a base mais desafiadora, com acur√°cia menor (0.69). A precis√£o (0.67) indica que o modelo erra mais ao classificar positivos, e o recall (0.71) mostra que ele n√£o recupera t√£o bem todos os positivos. Isso pode estar ligado ao vocabul√°rio mais variado dos textos de filmes, o que torna a classifica√ß√£o mais dif√≠cil.


AUC: Em todas as bases os valores foram satisfat√≥rios (acima de 0.75), mostrando que o modelo tem boa capacidade de separar classes positivas e negativas. O melhor resultado foi na Amazon (0.876), e o menor na IMDB (0.760), refor√ßando que essa √∫ltima √© mais complexa.

3.1. Curvas ROC

üìå Figura 1 ‚Äì Curva ROC para a base Amazon

<img width="578" height="455" alt="download" src="https://github.com/user-attachments/assets/b72f7736-3351-49f8-bec6-f04e1cd64b11" />

üìå Figura 2 ‚Äì Curva ROC para a base Yelp

<img width="578" height="455" alt="download" src="https://github.com/user-attachments/assets/f12f0b59-a911-42c7-9611-3c4eaa680cd0" />

üìå Figura 3 ‚Äì Curva ROC para a base IMDB

<img width="578" height="455" alt="download" src="https://github.com/user-attachments/assets/1ccd666a-e7d8-4bfe-a847-3468303331d0" />



4. Conclus√£o
Com base nos resultados apresentados:
O modelo Random Forest apresentou desempenho consistente, com acur√°cia em torno de 70‚Äì78% nas tr√™s bases.


Como as classes est√£o balanceadas, a acur√°cia √© confi√°vel, ou seja, o modelo n√£o ‚Äúacerta‚Äù s√≥ porque uma classe aparece mais vezes.


A precis√£o mais alta (Amazon e Yelp) mostra que o modelo foi bom em evitar falsos positivos nessas bases.


O recall da Amazon foi o melhor, indicando que a base era mais previs√≠vel em termos de vocabul√°rio. J√° a IMDB foi a mais dif√≠cil, com menor precis√£o e recall.


A AUC confirma que, mesmo com varia√ß√µes, o modelo consegue separar de forma razo√°vel as duas classes em todos os cen√°rios.


Em resumo, o pipeline TF-IDF + Random Forest √© adequado para classifica√ß√£o bin√°ria de textos curtos, mas o desempenho depende do tipo de vocabul√°rio e contexto de cada base.



