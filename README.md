# ğŸ“ Random Forest Text Classification

Este projeto tem como objetivo **classificar sentimentos em textos curtos** usando algoritmos de Machine Learning, com foco em **Random Forest**.  
Foram utilizados datasets rotulados de **reviews de produtos, restaurantes e filmes**, contendo frases positivas e negativas.

---

## ğŸ“‚ Estrutura do Projeto

random-forest-text-classification/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ amazon_cells_labelled.txt # reviews de produtos da Amazon
â”‚   â”œâ”€â”€ imdb_labelled.txt # reviews de filmes do IMDb
â”‚   â”œâ”€â”€ yelp_labelled.txt # reviews de restaurantes do Yelp
â”œâ”€â”€ SMSbasePOC.ipynb # notebook principal com todo o pipeline
â”œâ”€â”€ requirements.txt # bibliotecas necessÃ¡rias
â””â”€â”€ README.md # este arquivo

---

## ğŸ“Š Dataset
Foram utilizados trÃªs datasets de **sentiment analysis** do repositÃ³rio **UCI Machine Learning**:  
- **Amazon** â€“ OpiniÃµes sobre produtos eletrÃ´nicos.  
- **IMDb** â€“ AvaliaÃ§Ãµes de filmes.  
- **Yelp** â€“ Reviews de restaurantes.  

Cada dataset contÃ©m **1000 frases rotuladas** (500 positivas e 500 negativas).

---

## âš™ï¸ Tecnologias Utilizadas
- Python 3.x
- Bibliotecas:
  - `pandas`
  - `numpy`
  - `scikit-learn`
  - `matplotlib`
  - `seaborn`

---

## ğŸš€ Como Rodar o Projeto

### 1. Clone o repositÃ³rio
```bash
git clone https://github.com/LUC1NI/random-forest-text-classification.git
cd random-forest-text-classification

2. Crie o ambiente virtual e instale dependÃªncias
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows

pip install -r requirements.txt

3. Execute o notebook

Abra o Jupyter Notebook e rode:

jupyter notebook SMSbasePOC.ipynb

ğŸ” Etapas do Projeto

PrÃ©-processamento do texto

ConversÃ£o para minÃºsculas.

RemoÃ§Ã£o de pontuaÃ§Ãµes e stopwords.

VetorizaÃ§Ã£o usando Bag of Words.

Treinamento do modelo

Classificador Random Forest.

AvaliaÃ§Ã£o

MÃ©tricas: AcurÃ¡cia, PrecisÃ£o, Recall e F1-score.

ComparaÃ§Ã£o entre os trÃªs datasets.

ğŸ“ˆ Resultados

O modelo Random Forest apresentou bom desempenho nos trÃªs datasets.

As mÃ©tricas variaram dependendo do corpus, mas de forma geral:

IMDb â†’ melhor recall (detecÃ§Ã£o de frases negativas).

Amazon â†’ desempenho equilibrado entre precisÃ£o e recall.

Yelp â†’ melhores resultados de acurÃ¡cia.

ğŸ”¹ Mais anÃ¡lises e grÃ¡ficos podem ser adicionados em versÃµes futuras.

ğŸ“Œ ConclusÃµes

O projeto mostra que Random Forest Ã© eficaz em tarefas simples de classificaÃ§Ã£o de texto.

Resultados podem ser melhorados com:

RepresentaÃ§Ãµes mais avanÃ§adas (TF-IDF, embeddings).

ComparaÃ§Ã£o com outros algoritmos (Naive Bayes, Logistic Regression, SVM).

Este Ã© um bom projeto inicial de NLP para portfÃ³lio em Data Science.

âœ¨ Autor

ğŸ‘¤ JoÃ£o Lucini (LUC1NI)

GitHub: @LUC1NI